import{e as L,r as n,j as x,p as P,c as R}from"./pipelines-DTrqgdQT.js";L.allowRemoteModels=!0;const j="Xenova/bert-base-multilingual-cased",z=50;function f(e){return e.replace(/\[CLS\]/g,"").replace(/\[SEP\]/g,"").replace(/\[UNK\]/g,"").replace(/\s+/g," ").trim()}function b({initialText:e,modelName:a=j,topKPredictions:u=z}){const[S,s]=n.useState(e),[c,k]=n.useState(!0),[g,m]=n.useState(!1),d=n.useRef(null);n.useEffect(()=>{(async()=>{try{k(!0),d.current=await P("fill-mask",a)}catch(r){console.error("Failed to load pipeline:",r),s("Error loading model. Please check console.")}finally{k(!1)}})()},[a]);const T=n.useCallback(async()=>{if(c||g||!d.current)return;m(!0);const t=d.current;try{const r=e,w=await t.tokenizer(r,{addSpecialTokens:!0});console.log("Text is mixing.");let l=[...w.input_ids.data],i=[];for(let o=1;o<l.length-1;++o)i.push(o);let h=0;for(s(f(r));i.length>0&&h<20;){const o=i[Math.floor(Math.random()*i.length)],E=[...l];E[o]=t.tokenizer.mask_token_id;const y=await t.tokenizer.decode(E,{skipSpecialTokens:!1}),M=await t(y,{top_k:u});M.length>0&&(l[o]=M[0].token),i=i.filter(p=>p!==o),h+=1;const I=await t.tokenizer.decode(l,{skipSpecialTokens:!1});s(f(I)),await new Promise(p=>setTimeout(p,100))}const _=await t.tokenizer.decode(l,{skipSpecialTokens:!1});s(f(_))}catch(r){console.error("Error during text mixing:",r),s("Error mixing text. Please check console.")}finally{m(!1)}},[e,c,g,a,u]);return n.useEffect(()=>{!c&&d.current&&(s(e),T())},[e,c,T]),x.jsx("div",{children:x.jsx("p",{children:S})})}document.querySelectorAll("p.mix-me").forEach(e=>{const a=e.textContent;e.innerHTML="",R.createRoot(e).render(x.jsx(b,{initialText:a}))});
