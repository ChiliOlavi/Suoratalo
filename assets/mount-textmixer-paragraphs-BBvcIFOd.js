import{e as R,r as o,j as k,p as z,c as b}from"./pipelines-DTrqgdQT.js";R.allowRemoteModels=!0;const j="Xenova/bert-base-multilingual-cased",A=50;function S(e){return e.replace(/\[CLS\]/g,"").replace(/\[SEP\]/g,"").replace(/\[UNK\]/g,"").replace(/\s+/g," ").trim()}function C({initialText:e,modelName:a=j,topKPredictions:f=A}){const[w,i]=o.useState(e),[d,x]=o.useState(!0),[m,g]=o.useState(!1),u=o.useRef(null);o.useEffect(()=>{(async()=>{try{x(!0),u.current=await z("fill-mask",a)}catch(c){console.error("Failed to load pipeline:",c),i("Error loading model. Please check console.")}finally{x(!1)}})()},[a]);const E=o.useCallback(async()=>{if(d||m||!u.current)return;g(!0);const n=u.current;try{const c=e,_=await n.tokenizer(c,{addSpecialTokens:!0});console.log("Text is mixing.");let s=[..._.input_ids.data],r=[];for(let t=1;t<s.length-1;++t)r.push(t);let T=0;for(;r.length>0&&T<20;){const t=r[Math.floor(Math.random()*r.length)],h=[...s];h[t]=n.tokenizer.mask_token_id;const y=await n.tokenizer.decode(h,{skipSpecialTokens:!1}),p=await n(y,{top_k:f});if(p.length>0){const l=s[t],M=p.find(P=>P.token!==l);M?s[t]=M.token:s[t]=p[0].token}r=r.filter(l=>l!==t),T+=1;const L=await n.tokenizer.decode(s,{skipSpecialTokens:!1});i(S(L)),await new Promise(l=>setTimeout(l,100))}const I=await n.tokenizer.decode(s,{skipSpecialTokens:!1});i(S(I))}catch(c){console.error("Error during text mixing:",c),i("Error mixing text. Please check console.")}finally{g(!1)}},[e,d,m,a,f]);return o.useEffect(()=>{i(e)},[e]),o.useEffect(()=>{!d&&u.current&&E()},[e,d,E]),k.jsx(k.Fragment,{children:w})}document.querySelectorAll("p.mix-me").forEach(e=>{if(e.dataset.mixedMounted)return;e.dataset.mixedMounted="true";const a=e.textContent;e.innerHTML="",b.createRoot(e).render(k.jsx(C,{initialText:a}))});
