import{e as T,r as f,p as w,R as S,a as l}from"./pipelines-DJqUmFia.js";T.allowRemoteModels=!0;const R="Xenova/bert-base-multilingual-cased",M=50;function C(){console.log("App mounted");const c=f.useRef(null);f.useEffect(()=>{async function e(){c.current=await w("fill-mask",R),console.log("Model loaded, starting mixing");const t=Array.from(document.querySelectorAll(".container p"));console.log("Found paragraphs:",t.length);for(const a of t)console.log("Processing paragraph:",a.textContent.slice(0,60),"..."),k(a)}e()},[]);async function k(e){if(e.dataset.mixing==="true")return;e.dataset.mixing="true";const t=c.current,a=e.textContent;let d=[...(await t.tokenizer(a,{addSpecialTokens:!0})).input_ids.data],o=[];for(let n=1;n<d.length-1;++n)o.push(n);let s=[...d],p=0;for(e.textContent=r(a);o.length>0&&p<20;){const n=o[Math.floor(Math.random()*o.length)],u=[...s];u[n]=t.tokenizer.mask_token_id;const x=await t.tokenizer.decode(u,{skipSpecialTokens:!1}),g=await t(x,{top_k:M});g.length>0&&(s[n]=g[0].token),o=o.filter(i=>i!==n),p+=1;const h=await t.tokenizer.decode(s,{skipSpecialTokens:!1});e.textContent=r(h),await new Promise(i=>setTimeout(i,100))}const m=await t.tokenizer.decode(s,{skipSpecialTokens:!1});e.textContent=r(m),e.dataset.mixing="false"}function r(e){return e.replace(/\[CLS\]/g,"").replace(/\[SEP\]/g,"").replace(/\[UNK\]/g,"").replace(/\s+/g," ").trim()}return null}S.createRoot(document.getElementById("root")).render(l.createElement(l.StrictMode,null,l.createElement(C,null)));
