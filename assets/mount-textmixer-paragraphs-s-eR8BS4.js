import{e as L,r as n,a as k,p as P,c as R}from"./pipelines-DJqUmFia.js";L.allowRemoteModels=!0;const z="Xenova/bert-base-multilingual-cased",b=50;function f(e){return e.replace(/\[CLS\]/g,"").replace(/\[SEP\]/g,"").replace(/\[UNK\]/g,"").replace(/\s+/g," ").trim()}function v({initialText:e,modelName:r=z,topKPredictions:u=b}){const[S,s]=n.useState(e),[i,g]=n.useState(!0),[m,x]=n.useState(!1),d=n.useRef(null);n.useEffect(()=>{(async()=>{try{g(!0),d.current=await P("fill-mask",r),console.log(`Model "${r}" loaded.`)}catch(a){console.error("Failed to load pipeline:",a),s("Error loading model. Please check console.")}finally{g(!1)}})()},[r]);const E=n.useCallback(async()=>{if(i||m||!d.current)return;x(!0);const t=d.current;try{const a=e,w=await t.tokenizer(a,{addSpecialTokens:!0});console.log("Text is mixing.");let c=[...w.input_ids.data],l=[];for(let o=1;o<c.length-1;++o)l.push(o);let T=0;for(s(f(a));l.length>0&&T<20;){const o=l[Math.floor(Math.random()*l.length)],h=[...c];h[o]=t.tokenizer.mask_token_id;const y=await t.tokenizer.decode(h,{skipSpecialTokens:!1}),M=await t(y,{top_k:u});M.length>0&&(c[o]=M[0].token),l=l.filter(p=>p!==o),T+=1;const I=await t.tokenizer.decode(c,{skipSpecialTokens:!1});s(f(I)),await new Promise(p=>setTimeout(p,100))}const _=await t.tokenizer.decode(c,{skipSpecialTokens:!1});s(f(_))}catch(a){console.error("Error during text mixing:",a),s("Error mixing text. Please check console.")}finally{x(!1)}},[e,i,m,r,u]);return n.useEffect(()=>{!i&&d.current&&(s(e),E())},[e,i,E]),k.createElement("div",null,k.createElement("p",null,S))}document.querySelectorAll("p.mix-me").forEach(e=>{const r=e.textContent;e.innerHTML="",R.createRoot(e).render(k.createElement(v,{initialText:r}))});
